<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Composer by ntzhong</title>
    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/github-dark.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script>
    <script src="javascripts/respond.js"></script>
    <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <!--[if lt IE 8]>
    <link rel="stylesheet" href="stylesheets/ie.css">
    <![endif]-->
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

  </head>
  <body>
      <div id="header">
        <nav>
          <li class="fork"><a href="https://github.com/ntzhong/Composer">View On GitHub</a></li>
          <li class="downloads"><a href="https://github.com/ntzhong/Composer/zipball/master">ZIP</a></li>
          <li class="downloads"><a href="https://github.com/ntzhong/Composer/tarball/master">TAR</a></li>
          <li class="title">DOWNLOADS</li>
        </nav>
      </div><!-- end header -->

    <div class="wrapper">

      <section>
        <div id="title">
          <h1>Composer</h1>
          <p>A program that writes its own music</p>
          <hr>
          <span class="credits left">Project maintained by <a href="https://github.com/ntzhong">ntzhong</a></span>
          <span class="credits right">Hosted on GitHub Pages &mdash; Theme by <a href="https://twitter.com/michigangraham">mattgraham</a></span>
        </div>

        <p>For you TL;DR kind of people, here's a piece composed by the program: </p>

<p><a href="https://drive.google.com/open?id=0B-yYdO8MBojUWWtYVlBfVnhSUTQ">https://drive.google.com/open?id=0B-yYdO8MBojUWWtYVlBfVnhSUTQ</a></p>

<p>I was very surprised when I learned that musical automatons had already been in existence for at least several centuries. Perhaps most fascinating was David Roentgen's automaton modeled after Marie Antoinette in the 1700's. Roentgen's mechanical android strikes the strings of the instrument in perfect rhythm and with incredible precision, which is impressive given the technology available at the time.</p>

<p>Considering how far technology has advanced since then, I decided to take a crack at making my own autonomous instrument to see just how far we've come since then. But unlike the ones created during the renaissance and baroque periods, this instrument does not play preset pieces. Instead, it writes its own pieces. </p>

<p>I call this program Composer (great naming sense, I know). This project explores the possibilities of music intelligence by first developing a program that can adhere to fundamental rules of western music theory, then then expanding on the program by attempting to imbue it with my own compositional style and preferences. Because this idea was, at the time, quite abstract, I decided to go for a more straight-forward implementation that involves hard-coding my own rules and probability distributions, rather than tackling it from an artificial intelligence and machine-learning standpoint.</p>

<p>Throughout the history of autonomous instruments, the question of who or what deserves credit for the sounds produced by the instrument has always been a point of ambiguity. Dating back to the days of the first Automatons, the answer to this question was a little more clear-cut: because automatons were configured by craftsmen to play preset songs with no degrees of freedom, it's not hard to say that the crafstmen are responsible for the music produced by these automatons.</p>

<p>However, as we transitioned into the classical and romantic era, this question becomes blurred with the arrival of instruments like the Aeolian harp. Although the creator(s) of the harp designed the harp so that it could produce strange sounds and chords, they have no control over what sounds the harp actually produces.</p>

<p>Throughout the process of designing and implementing this program, I was able to further examine this question by applying it to myself and this program. The program makes its own decisions in composing its own song, from constructing chord progressions to deciding it's own rhythm and notes. However, I, the creator, gave the program a set of rules by which to follow when making these decisions. In a sense, I have a hand in directly influencing the decisions the program makes. Taking all this into consideration, would I, the creator, be considered the composer? Can I claim the product of this program as my own composition (not that I would want to given the quality)? Or is the program the true composer?</p>

<p>As it turns out, the answer is not all black or white. It is a spectrum that really boils down to intention and design. For the automatons back in the baroque period, the crafstmen designed every parameter with intention, and can predict and control, absolutely, the outcome of each parameter. In a way, this is analagous to writing out a song note by note. In my case, however, I've designed the program to make its own decisions, given a loose set of rules that must be followed. I can influence the results, but I do not have absolute control over the outcome. For this reason, I cannot say that I composed the pieces written by the program. Although I intended it to closely follow my own improvisation style (it currently doesn't do that very well), I do not have any more control beyond that. In a way, it's like I am the teacher, and the program is my student. I taught the program how to play, but that's all I did.</p>

<p>So in my case, it's a little bit of both. Because a lot of the rules were hard-coded, I am largely responsible for the outcome, yet it is the program that makes the final decision. If, however, I had instead approached program from a machine-learning perspective, feeding it tons of MIDI files from which it could construct its own learning tree, my answer would be very different. In that case, I would say I had no part in the compositions the program writes, because I no longer have the role of teaching the program. Instead, I'd be the mother that hires a teacher for her kid.</p>

<h3>
<a id="results" class="anchor" href="#results" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Results:</h3>

<p>As expected, it was very difficult trying to capture such an abstract art with such a rigid and straight-forward implementation. The quality of the music produced is a hit or a miss. Every so often, there may be a musical phrase that sounds like it could develop into something with real potential, and on occasion I'll hear bits and pieces that very closely resembles my style of improvisation. But for the most part, the compositions are pretty bland, and on occasion falls apart musically.</p>

<p>On the bright side, this did turn out better than I thought it would. I realized it is not difficult to string together a coherent string of notes. Perhaps the greatest difficulty in creating something truly musical and interesting phrase is making the program context-aware. I've only tried implementing some context-aware rules (more likely to move in smaller intervals than large ones, follow ascension/descension patterns, so it doesnt just jump up and down the scale every other note, etc), but there are plenty more that I have in mind that I'd like to play around with in the near future. My problem is that I did not structure the code in such a way that I can easily add context-aware features without making the code messier than it already is.</p>

<p>This program can compose in both major and minor key. Currently, I'm omitting chords until I can get an acceptable level of quality in the music.</p>

<p>Here are the results: </p>

<p>This one's pretty consistent. nothing special, but I do think it sounds pleasant. This is probably how the average composition sounds like.
<a href="https://drive.google.com/open?id=0B-yYdO8MBojUWWtYVlBfVnhSUTQ">https://drive.google.com/open?id=0B-yYdO8MBojUWWtYVlBfVnhSUTQ</a></p>

<p>This is the most recent file generated by the program.
<a href="https://drive.google.com/open?id=0B-yYdO8MBojUNmpnVkRQUHFucVE">https://drive.google.com/open?id=0B-yYdO8MBojUNmpnVkRQUHFucVE</a></p>

<p>Here's another minor one. This one actually gets pretty interesting during the last 15 or so seconds.
<a href="https://drive.google.com/open?id=0B-yYdO8MBojUSE1KVnFFTGRYNGs">https://drive.google.com/open?id=0B-yYdO8MBojUSE1KVnFFTGRYNGs</a></p>

<p>This one starts off rough, but actually gets decent around 0:22:
<a href="https://drive.google.com/open?id=0B-yYdO8MBojURldreWF4aDQ2VEE">https://drive.google.com/open?id=0B-yYdO8MBojURldreWF4aDQ2VEE</a></p>

<p>Here are a few examples of pieces that started off pretty well, but fall apart
comps/interestingstart.mid
<a href="https://drive.google.com/open?id=0B-yYdO8MBojUSXF2UzhDR0NwWWM">https://drive.google.com/open?id=0B-yYdO8MBojUSXF2UzhDR0NwWWM</a></p>

<p>The first 8 seconds are pretty fun, then it completely falls apart, haha.
<a href="https://drive.google.com/open?id=0B-yYdO8MBojUVzBfOHB2US1TY2c">https://drive.google.com/open?id=0B-yYdO8MBojUVzBfOHB2US1TY2c</a></p>

<p>This is exactly what I mean by "bland". The notes do not go anywhere.
<a href="https://drive.google.com/open?id=0B-yYdO8MBojUUDVZUktnZVBlQ1E">https://drive.google.com/open?id=0B-yYdO8MBojUUDVZUktnZVBlQ1E</a></p>

<p>The original files are in MIDI format, so you can easily convert it into sheet-music using programs such as Noteflight or Finale.</p>

<h3>
<a id="future-steps" class="anchor" href="#future-steps" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>FUTURE STEPS:</h3>

<p>As it turns out, David Cope had already tried this decades ago, and like he, I realized that it's very difficult to try to capture the abstractness of music with such an inflexible and straight-forward implementation. Sure, it's definitely possible, but it would require a ton of code, and will probably become very messy, very quickly.</p>

<p>Perhaps the best option would be to approach this problem from an artificial intelligence standpoint. Like I mentioned above, one solution is, perhaps, carefully parsing a batch of similarly-styled MIDI files and and aggregating the data into a structured decision tree, such that tree depth corresponds to time or beat number. I think, if structured carefully, the tree would be unconditionally context-aware, and doing a linear traversal down random branches should result in a song that flows.</p>

<p>This idea is similar to David Cope's idea of recombinance, where Cope suggests breaking down and recombining parts from different pieces to create a new piece. However, rather than relying on the recombination of parts to create a piece, I want to instead use these parts as a means to teach the program certain subtle musical tendencies, which it could then use as a guideline to create something entirely new.</p>
      </section>

    </div>
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->
    
  </body>
</html>
