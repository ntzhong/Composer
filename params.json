{
  "name": "Composer",
  "tagline": "A program that writes its own music",
  "body": "I was very surprised when I learned that musical automatons had already been in existence for at least several centuries. Perhaps most fascinating was David Roentgen's automaton modeled after Marie Antoinette in the 1700's. Roentgen's mechanical android strikes the strings of the instrument in perfect rhythm and with incredible precision, which is impressive given the technology available at the time.\r\n\r\nConsidering how far technology has advanced since then, I decided to take a crack at making my own autonomous instrument to see just how far we've come since then. But unlike the ones created during the renaissance and baroque periods, this instrument does not play preset pieces. Instead, it writes its own pieces. \r\n\r\nI call this program Composer (great naming sense, I know). This project explores the possibilities of music intelligence by first developing a program that can adhere to fundamental rules of western music theory, then then expanding on the program by attempting to imbue it with my own compositional style and preferences. Because this idea was, at the time, quite abstract, I decided to go for a more straight-forward implementation that involves hard-coding my own rules and probability distributions, rather than tackling it from an artificial intelligence and machine-learning standpoint.\r\n\r\nThroughout the history of autonomous instruments, the question of who or what deserves credit for the sounds produced by the instrument has always been a point of ambiguity. Dating back to the days of the first Automatons, the answer to this question was a little more clear-cut: because automatons were configured by craftsmen to play preset songs with no degrees of freedom, it's not hard to say that the crafstmen are responsible for the music produced by these automatons.\r\n\r\nHowever, as we transitioned into the classical and romantic era, this question becomes blurred with the arrival of instruments like the Aeolian harp. Although the creator(s) of the harp designed the harp so that it could produce strange sounds and chords, they have no control over what sounds the harp actually produces.\r\n\r\nThroughout the process of designing and implementing this program, I was able to further examine this question by applying it to myself and this program. The program makes its own decisions in composing its own song, from constructing chord progressions to deciding it's own rhythm and notes. However, I, the creator, gave the program a set of rules by which to follow when making these decisions. In a sense, I have a hand in directly influencing the decisions the program makes. Taking all this into consideration, would I, the creator, be considered the composer? Can I claim the product of this program as my own composition (not that I would want to given the quality)? Or is the program the true composer?\r\n\r\nAs it turns out, the answer is not all black or white. It is a spectrum that really boils down to intention and design. For the automatons back in the baroque period, the crafstmen designed every parameter with intention, and can predict and control, absolutely, the outcome of each parameter. In a way, this is analagous to writing out a song note by note. In my case, however, I've designed the program to make its own decisions, given a loose set of rules that must be followed. I can influence the results, but I do not have absolute control over the outcome. For this reason, I cannot say that I composed the pieces written by the program. Although I intended it to closely follow my own improvisation style (it currently doesn't do that very well), I do not have any more control beyond that. In a way, it's like I am the teacher, and the program is my student. I taught the program how to play, but that's all I did.\r\n\r\nSo in my case, it's a little bit of both. Because a lot of the rules were hard-coded, I am largely responsible for the outcome, yet it is the program that makes the final decision. If, however, I had instead approached program from a machine-learning perspective, feeding it tons of MIDI files from which it could construct its own learning tree, my answer would be very different. In that case, I would say I had no part in the compositions the program writes, because I no longer have the role of teaching the program. Instead, I'd be the mother that hires a teacher for her kid.\r\n\r\n\r\n###Results:\r\nAs expected, it was very difficult trying to capture such an abstract art with such a rigid and straight-forward implementation. The quality of the music produced is a hit or a miss. Every so often, there may be a musical phrase that sounds like it could develop into something with real potential, and on occasion I'll hear bits and pieces that very closely resembles my style of improvisation. But for the most part, the compositions are pretty bland, and on occasion falls apart musically.\r\n\r\nOn the bright side, this did turn out better than I thought it would. I realized it is not difficult to string together a coherent string of notes. Perhaps the greatest difficulty in creating something truly musical and interesting phrase is making the program context-aware. I've only tried implementing some context-aware rules (more likely to move in smaller intervals than large ones, follow ascension/descension patterns, so it doesnt just jump up and down the scale every other note, etc), but there are plenty more that I have in mind that I'd like to play around with in the near future. My problem is that I did not structure the code in such a way that I can easily add context-aware features without making the code messier than it already is.\r\n\r\nThis program can compose in both major and minor key. Currently, I'm omitting chords until I can get an acceptable level of quality in the music.\r\n\r\nHere are the results: \r\n\r\nThis is the most recent file generated by the program. This represents the average quality.\r\n\r\nout.mid\r\n\r\nHere are some other minor ones:\r\n\r\ncomps/out.mid\r\n\r\ncomps/minor.mid\r\n\r\nHere are a few examples of pieces that started off pretty well, but fall apart\r\n\r\ncomps/interestingstart.mid\r\n\r\ncomps/stage1/goodstart.mid\r\n\r\n\r\nThis one starts off rough, but actually gets decent around 0:22:\r\n\r\ncomps/okayMiddle.mid\r\n\r\n\r\nothers:\r\n\r\ncomps/1.mid\r\n\r\nThis one's pretty consistent. nothing special, but I do think it sounds pleasant\r\n\r\nstage2/consistent.mid\r\n\r\n\r\n\r\n###FUTURE STEPS:\r\nAs it turns out, David Cope had already tried this decades ago, and like he, I realized that it's very difficult to try to capture the abstractness of music with such an inflexible and straight-forward implementation. Sure, it's definitely possible, but it would require a ton of code, and will probably become very messy, very quickly.\r\n\r\nPerhaps the best option would be to approach this problem from an artificial intelligence standpoint. Like I mentioned above, one solution is, perhaps, carefully parsing a batch of similarly-styled MIDI files and and aggregating the data into a structured decision tree, such that tree depth corresponds to time or beat number. I think, if structured carefully, the tree would be unconditionally context-aware, and doing a linear traversal down random branches should result in a song that flows.\r\n\r\nThis idea is similar to David Cope's idea of recombinance, where Cope suggests breaking down and recombining parts from different pieces to create a new piece. However, rather than relying on the recombination of parts to create a piece, I want to instead use these parts as a means to teach the program certain subtle musical tendencies, which it could then use as a guideline to create something entirely new.\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}